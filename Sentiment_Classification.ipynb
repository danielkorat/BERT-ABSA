{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielkorat/BERT-ABSA/blob/master/Sentiment_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLUsPMnNO040"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XJVv9j6euja"
      },
      "source": [
        "## Select backend and pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK2R4F3zEig6"
      },
      "source": [
        "BACKEND = 'tf' # or 'pt'\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "DO_TRAIN = True\n",
        "DO_PREDICT = True\n",
        "\n",
        "SMOKE_TEST = True"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9Rh3jR0Ow2O"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "source": [
        "from sys import executable as python\n",
        "!{python} -m pip install -q -q transformers==4.4.2\n",
        "\n",
        "if BACKEND == 'tf':\n",
        "    !{python} -m pip install -q -q tensorflow==2.4.1\n",
        "if BACKEND == 'pt':\n",
        "    !{python} -m pip install -q -q torch==1.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgLu3bJnAYdG"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "if BACKEND == 'tf':\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.data import Dataset\n",
        "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "    from transformers import TFAutoModelForSequenceClassification as model_cls\n",
        "    from transformers import TFTrainer as trainer_cls\n",
        "    from transformers import TFTrainingArguments as training_args_cls\n",
        "\n",
        "if BACKEND == 'pt':\n",
        "    import torch\n",
        "\n",
        "    from transformers import AutoModelForSequenceClassification as model_cls\n",
        "    from transformers import Trainer as trainer_cls\n",
        "    from transformers import TrainingArguments as training_args_cls\n",
        "\n",
        "import transformers\n",
        "transformers.logging.set_verbosity_info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pchfjwUFzho"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVvslsfMIrIh"
      },
      "source": [
        "! wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "! tar -xf aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UEH0gioFrrZ"
      },
      "source": [
        "# Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IreSlFmlIrIm"
      },
      "source": [
        "def read_imdb_split(split_dir):\n",
        "    split_dir = Path(split_dir)\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for label_dir in [\"pos\", \"neg\"]:\n",
        "        for text_file in (split_dir/label_dir).iterdir():\n",
        "            texts.append(text_file.read_text())\n",
        "            labels.append(0 if label_dir is \"neg\" else 1)\n",
        "    return texts, labels\n",
        "\n",
        "train_texts, train_labels = read_imdb_split('aclImdb/train')\n",
        "test_texts, test_labels = read_imdb_split('aclImdb/test')\n",
        "\n",
        "if SMOKE_TEST:\n",
        "    train_texts, train_labels = train_texts[:500], train_labels[:500]\n",
        "    test_texts, test_labels = test_texts[:200], test_labels[:200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VDhZdGzGAI7"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g15w2KnErjJi"
      },
      "source": [
        "## Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-TnMJBzF-9L"
      },
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPvBNMufGWnv"
      },
      "source": [
        "## Convert to tensor dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLe2oB3j4dfC"
      },
      "source": [
        "if BACKEND == 'tf':\n",
        "    train_dataset = Dataset.from_tensor_slices((dict(train_encodings), train_labels))\n",
        "    test_dataset = Dataset.from_tensor_slices((dict(test_encodings), test_labels))\n",
        "\n",
        "if BACKEND == 'pt':\n",
        "    class IMDbDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = encodings\n",
        "            self.labels = labels\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    train_dataset = IMDbDataset(train_encodings, train_labels)\n",
        "    test_dataset = IMDbDataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0DC-LJ4f4kH"
      },
      "source": [
        "# Training arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_VTn1RFflJo"
      },
      "source": [
        "training_args = training_args_cls(\n",
        "    output_dir='./results',             # output directory\n",
        "    num_train_epochs=5,                 # total number of training epochs\n",
        "    max_steps=20 if SMOKE_TEST else -1, # total number of training steps (overrides `num_train_epochs`)\n",
        "    per_device_train_batch_size=16,     # batch size per device during training\n",
        "    warmup_steps=500,                   # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,                  # strength of weight decay\n",
        "    logging_dir='./logs',               # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scsOJo_Jrr2-"
      },
      "source": [
        "# Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz26uXQKrygV"
      },
      "source": [
        "if BACKEND == 'tf':\n",
        "    with training_args.strategy.scope():\n",
        "        model = model_cls.from_pretrained(MODEL_NAME)\n",
        "if BACKEND == 'pt':\n",
        "    model = model_cls.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o68quzEIDkrg"
      },
      "source": [
        "trainer = trainer_cls(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbDjliR_GrKg"
      },
      "source": [
        "# Fine-Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqmRntBGHlCp"
      },
      "source": [
        "if DO_TRAIN:\n",
        "    trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6B4xopCGzAR"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b-JiW7JBiMB"
      },
      "source": [
        "if DO_PREDICT:\n",
        "    trainer.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}